<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>kafka入门：简介、使用场景、设计原理、主要配置及集群搭建</title>
    <url>/1376638572.html</url>
    <content><![CDATA[<h3 id="Kafka简介使用场景设计原理"><a href="#Kafka简介使用场景设计原理" class="headerlink" title="Kafka简介使用场景设计原理"></a>Kafka简介使用场景设计原理</h3><p><em>关于kafka说明可以参考：<a href="http://kafka.apache.org/documentation.html" target="_blank" rel="noopener">http://kafka.apache.org/documentation.html</a></em></p>
<p><em>文章转自：<a href="http://www.aboutyun.com/thread-9341-1-1.html" target="_blank" rel="noopener">http://www.aboutyun.com/thread-9341-1-1.html</a></em></p>
<h4 id="问题导读："><a href="#问题导读：" class="headerlink" title="问题导读："></a>问题导读：</h4><ol>
<li>zookeeper在kafka的作用是什么？  </li>
<li>kafka中几乎不允许对消息进行“随机读写”的原因是什么？</li>
<li>kafka集群consumer和producer状态信息是如何保存的？</li>
<li>partitions设计的目的的根本原因是什么？</li>
</ol>
<a id="more"></a>
<h4 id="一、入门"><a href="#一、入门" class="headerlink" title="一、入门"></a>一、入门</h4><h5 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h5><p>Kafka is a distributed,partitioned,replicated commit logservice。它提供了类似于JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现。kafka对消息保存时根据Topic进行归类，发送消息者成为Producer,消息接受者成为Consumer,此外kafka集群有多个kafka实例组成，每个实例(server)成为broker。无论是kafka集群，还是producer和consumer都依赖于zookeeper来保证系统可用性集群保存一些meta信息。</p>
<p><img src="/images/100009.png" alt="avatar"></p>
<h5 id="2、Topics-logs"><a href="#2、Topics-logs" class="headerlink" title="2、Topics/logs"></a>2、Topics/logs</h5><p>一个Topic可以认为是一类消息，每个topic将被分成多个partition(区),每个partition在存储层面是append log文件。任何发布到此partition的消息都会被直接追加到log文件的尾部，每条消息在文件中的位置称为offset（偏移量），offset为一个long型数字，它是唯一标记一条消息。它唯一的标记一条消息。kafka并没有提供其他额外的索引机制来存储offset，因为在kafka中几乎不允许对消息进行“随机读写”。</p>
<p><img src="/images/100010.png" alt="avatar"></p>
<p>kafka和JMS（Java Message Service）实现(activeMQ)不同的是:即使消息被消费,消息仍然不会被立即删除.日志文件将会根据broker中的配置要求,保留一定的时间之后删除;比如log文件保留2天,那么两天后,文件会被清除,无论其中的消息是否被消费.kafka通过这种简单的手段,来释放磁盘空间,以及减少消息消费之后对文件内容改动的磁盘IO开支.</p>
<p>对于consumer而言,它需要保存消费消息的offset,对于offset的保存和使用,有consumer来控制;当consumer正常消费消息时,offset将会”线性”的向前驱动,即消息将依次顺序被消费.事实上consumer可以使用任意顺序消费消息,它只需要将offset重置为任意值..(offset将会保存在zookeeper中,参见下文)</p>
<p>kafka集群几乎不需要维护任何consumer和producer状态信息,这些信息有zookeeper保存;因此producer和consumer的客户端实现非常轻量级,它们可以随意离开,而不会对集群造成额外的影响.</p>
<p>partitions的设计目的有多个.最根本原因是kafka基于文件存储.通过分区,可以将日志内容分散到多个server上,来避免文件尺寸达到单机磁盘的上限,每个partiton都会被当前server(kafka实例)保存;可以将一个topic切分多任意多个partitions,来消息保存/消费的效率.此外越多的partitions意味着可以容纳更多的consumer,有效提升并发消费的能力.(具体原理参见下文).</p>
<h5 id="3、Distribution"><a href="#3、Distribution" class="headerlink" title="3、Distribution"></a>3、Distribution</h5><p>一个Topic的多个partitions,被分布在kafka集群中的多个server上;每个server(kafka实例)负责partitions中消息的读写操作;此外kafka还可以配置partitions需要备份的个数(replicas),每个partition将会被备份到多台机器上,以提高可用性.</p>
<p>基于replicated方案,那么就意味着需要对多个备份进行调度;每个partition都有一个server为”leader”;leader负责所有的读写操作,如果leader失效,那么将会有其他follower来接管(成为新的leader);follower只是单调的和leader跟进,同步消息即可..由此可见作为leader的server承载了全部的请求压力,因此从集群的整体考虑,有多少个partitions就意味着有多少个”leader”,kafka会将”leader”均衡的分散在每个实例上,来确保整体的性能稳定.</p>
<p>Producers<br>Producer将消息发布到指定的Topic中,同时Producer也能决定将此消息归属于哪个partition;比如基于”round-robin”方式或者通过其他的一些算法等.</p>
<p>Consumers<br>本质上kafka只支持Topic.每个consumer属于一个consumer group;反过来说,每个group中可以有多个consumer.发送到Topic的消息,只会被订阅此Topic的每个group中的一个consumer消费.</p>
<p>如果所有的consumer都具有相同的group,这种情况和queue模式很像;消息将会在consumers之间负载均衡.<br>如果所有的consumer都具有不同的group,那这就是”发布-订阅”;消息将会广播给所有的消费者.<br>在kafka中,一个partition中的消息只会被group中的一个consumer消费;每个group中consumer消息消费互相独立;我们可以认为一个group是一个”订阅”者,一个Topic中的每个partions,只会被一个”订阅者”中的一个consumer消费,不过一个consumer可以消费多个partitions中的消息.kafka只能保证一个partition中的消息被某个consumer消费时,消息是顺序的.事实上,从Topic角度来说,消息仍不是有序的.</p>
<p>kafka的设计原理决定,对于一个topic,同一个group中不能有多于partitions个数的consumer同时消费,否则将意味着某些consumer将无法得到消息.</p>
<p>Guarantees</p>
<p>1) 发送到partitions中的消息将会按照它接收的顺序追加到日志中<br>2) 对于消费者而言,它们消费消息的顺序和日志中消息顺序一致.<br>3) 如果Topic的”replicationfactor”为N,那么允许N-1个kafka实例失效.</p>
<h4 id="二、使用场景"><a href="#二、使用场景" class="headerlink" title="二、使用场景"></a>二、使用场景</h4><h5 id="1、Messaging"><a href="#1、Messaging" class="headerlink" title="1、Messaging"></a>1、Messaging</h5><p>对于一些常规的消息系统,kafka是个不错的选择;partitons/replication和容错,可以使kafka具有良好的扩展性和性能优势.不过到目前为止,我们应该很清楚认识到,kafka并没有提供JMS中的”事务性””消息传输担保(消息确认机制)””消息分组”等企业级特性;kafka只能使用作为”常规”的消息系统,在一定程度上,尚未确保消息的发送与接收绝对可靠(比如,消息重发,消息发送丢失等)</p>
<h5 id="2、Websit-activity-tracking"><a href="#2、Websit-activity-tracking" class="headerlink" title="2、Websit activity tracking"></a>2、Websit activity tracking</h5><p>kafka可以作为”网站活性跟踪”的最佳工具;可以将网页/用户操作等信息发送到kafka中.并实时监控,或者离线统计分析等</p>
<h5 id="3、Log-Aggregation"><a href="#3、Log-Aggregation" class="headerlink" title="3、Log Aggregation"></a>3、Log Aggregation</h5><p>kafka的特性决定它非常适合作为”日志收集中心”;application可以将操作日志”批量””异步”的发送到kafka集群中,而不是保存在本地或者DB中;kafka可以批量提交消息/压缩消息等,这对producer端而言,几乎感觉不到性能的开支.此时consumer端可以使hadoop等其他系统化的存储和分析系统.</p>
<h4 id="三、设计原理"><a href="#三、设计原理" class="headerlink" title="三、设计原理"></a>三、设计原理</h4><p>kafka的设计初衷是希望作为一个统一的信息收集平台,能够实时的收集反馈信息,并需要能够支撑较大的数据量,且具备良好的容错能力.</p>
<h5 id="1、持久性"><a href="#1、持久性" class="headerlink" title="1、持久性"></a>1、持久性</h5><p>kafka使用文件存储消息,这就直接决定kafka在性能上严重依赖文件系统的本身特性.且无论任何OS下,对文件系统本身的优化几乎没有可能.文件缓存/直接内存映射等是常用的手段.因为kafka是对日志文件进行append操作,因此磁盘检索的开支是较小的;同时为了减少磁盘写入的次数,broker会将消息暂时buffer起来,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数.</p>
<h5 id="2、性能"><a href="#2、性能" class="headerlink" title="2、性能"></a>2、性能</h5><p>需要考虑的影响性能点很多,除磁盘IO之外,我们还需要考虑网络IO,这直接关系到kafka的吞吐量问题.kafka并没有提供太多高超的技巧;对于producer端,可以将消息buffer起来,当消息的条数达到一定阀值时,批量发送给broker;对于consumer端也是一样,批量fetch多条消息.不过消息量的大小可以通过配置文件来指定.对于kafka broker端,似乎有个sendfile系统调用可以潜在的提升网络IO的性能:将文件的数据映射到系统内存中,socket直接读取相应的内存区域即可,而无需进程再次copy和交换. 其实对于producer/consumer/broker三者而言,CPU的开支应该都不大,因此启用消息压缩机制是一个良好的策略;压缩需要消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑.可以将任何在网络上传输的消息都经过压缩.kafka支持gzip/snappy等多种压缩方式.</p>
<h5 id="3、生产者"><a href="#3、生产者" class="headerlink" title="3、生产者"></a>3、生产者</h5><p>负载均衡: producer将会和Topic下所有partition leader保持socket连接;消息由producer直接通过socket发送到broker,中间不会经过任何”路由层”.事实上,消息被路由到哪个partition上,有producer客户端决定.比如可以采用”random””key-hash””轮询”等,如果一个topic中有多个partitions,那么在producer端实现”消息均衡分发”是必要的.</p>
<p>其中partition leader的位置(host:port)注册在zookeeper中,producer作为zookeeper client,已经注册了watch用来监听partition leader的变更事件.<br>异步发送：将多条消息暂且在客户端buffer起来，并将他们批量的发送到broker，小数据IO太多，会拖慢整体的网络延迟，批量延迟发送事实上提升了网络效率。不过这也有一定的隐患，比如说当producer失效时，那些尚未发送的消息将会丢失。</p>
<h5 id="4、消费者"><a href="#4、消费者" class="headerlink" title="4、消费者"></a>4、消费者</h5><p>consumer端向broker发送”fetch”请求,并告知其获取消息的offset;此后consumer将会获得一定条数的消息;consumer端也可以重置offset来重新消费消息.</p>
<p>在JMS实现中,Topic模型基于push方式,即broker将消息推送给consumer端.不过在kafka中,采用了pull方式,即consumer在和broker建立连接之后,主动去pull(或者说fetch)消息;这中模式有些优点,首先consumer端可以根据自己的消费能力适时的去fetch消息并处理,且可以控制消息消费的进度(offset);此外,消费者可以良好的控制消息消费的数量,batch fetch.</p>
<p>其他JMS实现,消息消费的位置是有prodiver保留,以便避免重复发送消息或者将没有消费成功的消息重发等,同时还要控制消息的状态.这就要求JMS broker需要太多额外的工作.在kafka中,partition中的消息只有一个consumer在消费,且不存在消息状态的控制,也没有复杂的消息确认机制,可见kafka broker端是相当轻量级的.当消息被consumer接收之后,consumer可以在本地保存最后消息的offset,并间歇性的向zookeeper注册offset.由此可见,consumer客户端也很轻量级.</p>
<p><img src="/images/100011.png" alt="avatar"></p>
<h5 id="5、消息传送机制"><a href="#5、消息传送机制" class="headerlink" title="5、消息传送机制"></a>5、消息传送机制</h5><p>对于JMS实现,消息传输担保非常直接:有且只有一次(exactly once).在kafka中稍有不同:</p>
<ol>
<li>at most once: 最多一次,这个和JMS中”非持久化”消息类似.发送一次,无论成败,将不会重发.</li>
<li>at least once: 消息至少发送一次,如果消息未能接受成功,可能会重发,直到接收成功.</li>
<li>exactly once: 消息只会发送一次.</li>
<li>at most once: 消费者fetch消息,然后保存offset,然后处理消息;当client保存offset之后,但是在消息处理过程中出现了异常,导致部分消息未能继续处理.那么此后”未处理”的消息将不能被fetch到,这就是”at most once”.</li>
<li>at least once: 消费者fetch消息,然后处理消息,然后保存offset.如果消息处理成功之后,但是在保存offset阶段zookeeper异常导致保存操作未能执行成功,这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是”at least once”，原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态.</li>
<li>exactly once: kafka中并没有严格的去实现(基于2阶段提交,事务),我们认为这种策略在kafka中是没有必要的.</li>
</ol>
<p>通常情况下”at-least-once”是我们首选.(相比at most once而言,重复接收数据总比丢失数据要好).</p>
<h5 id="6、复制备份"><a href="#6、复制备份" class="headerlink" title="6、复制备份"></a>6、复制备份</h5><p>kafka将每个partition数据复制到多个server上,任何一个partition有一个leader和多个follower(可以没有);备份的个数可以通过broker配置文件来设定.leader处理所有的read-write请求,follower需要和leader保持同步.Follower和consumer一样,消费消息并保存在本地日志中;leader负责跟踪所有的follower状态,如果follower”落后”太多或者失效,leader将会把它从replicas同步列表中删除.当所有的follower都将一条消息保存成功,此消息才被认为是”committed”,那么此时consumer才能消费它.即使只有一个replicas实例存活,仍然可以保证消息的正常发送和接收,只要zookeeper集群存活即可.(不同于其他分布式存储,比如hbase需要”多数派”存活才行)</p>
<p>当leader失效时,需在followers中选取出新的leader,可能此时follower落后于leader,因此需要选择一个”up-to-date”的follower.选择follower时需要兼顾一个问题,就是新leaderserver上所已经承载的partition leader的个数,如果一个server上有过多的partition leader,意味着此server将承受着更多的IO压力.在选举新leader,需要考虑到”负载均衡”.</p>
<h5 id="7-日志"><a href="#7-日志" class="headerlink" title="7.日志"></a>7.日志</h5><p>如果一个topic的名称为”my_topic”,它有2个partitions,那么日志将会保存在my_topic_0和my_topic_1两个目录中;日志文件中保存了一序列”log entries”(日志条目),每个log entry格式为”4个字节的数字N表示消息的长度” + “N个字节的消息内容”;每个日志都有一个offset来唯一的标记一条消息,offset的值为8个字节的数字,表示此消息在此partition中所处的起始位置..每个partition在物理存储层面,有多个log file组成(称为segment).segmentfile的命名为”最小offset”.kafka.例如”00000000000.kafka”;其中”最小offset”表示此segment中起始消息的offset.</p>
<p><img src="/images/100012.png" alt="avatar"></p>
<p>其中每个partiton中所持有的segments列表信息会存储在zookeeper中.</p>
<p>当segment文件尺寸达到一定阀值时(可以通过配置文件设定,默认1G),将会创建一个新的文件;当buffer中消息的条数达到阀值时将会触发日志信息flush到日志文件中,同时如果”距离最近一次flush的时间差”达到阀值时,也会触发flush到日志文件.如果broker失效,极有可能会丢失那些尚未flush到文件的消息.因为server意外实现,仍然会导致log文件格式的破坏(文件尾部),那么就要求当server启东是需要检测最后一个segment的文件结构是否合法并进行必要的修复.</p>
<p>获取消息时,需要指定offset和最大chunk尺寸,offset用来表示消息的起始位置,chunk size用来表示最大获取消息的总长度(间接的表示消息的条数).根据offset,可以找到此消息所在segment文件,然后根据segment的最小offset取差值,得到它在file中的相对位置,直接读取输出即可.</p>
<p>日志文件的删除策略非常简单:启动一个后台线程定期扫描log file列表,把保存时间超过阀值的文件直接删除(根据文件的创建时间).为了避免删除文件时仍然有read操作(consumer消费),采取copy-on-write方式.</p>
<h5 id="8、分配"><a href="#8、分配" class="headerlink" title="8、分配"></a>8、分配</h5><p>kafka使用zookeeper来存储一些meta信息,并使用了zookeeper watch机制来发现meta信息的变更并作出相应的动作(比如consumer失效,触发负载均衡等)</p>
<ol>
<li><p>Broker node registry: 当一个kafkabroker启动后,首先会向zookeeper注册自己的节点信息(临时znode),同时当broker和zookeeper断开连接时,此znode也会被删除.<br> 格式: /broker/ids/[0…N]   –&gt;host:port;其中[0..N]表示broker id,每个broker的配置文件中都需要指定一个数字类型的id(全局不可重复),znode的值为此broker的host:port信息.</p>
</li>
<li><p>Broker Topic Registry: 当一个broker启动时,会向zookeeper注册自己持有的topic和partitions信息,仍然是一个临时znode.<br> 格式: /broker/topics/[topic]/[0…N]  其中[0..N]表示partition索引号.</p>
</li>
<li><p>Consumer and Consumer group: 每个consumer客户端被创建时,会向zookeeper注册自己的信息;此作用主要是为了”负载均衡”.<br> 一个group中的多个consumer可以交错的消费一个topic的所有partitions;简而言之,保证此topic的所有partitions都能被此group所消费,且消费时为了性能考虑,让partition相对均衡的分散到每个consumer上.</p>
</li>
<li><p>Consumer id Registry: 每个consumer都有一个唯一的ID(host:uuid,可以通过配置文件指定,也可以由系统生成),此id用来标记消费者信息.<br> 格式:/consumers/[group_id]/ids/[consumer_id]<br> 仍然是一个临时的znode,此节点的值为{“topic_name”:#streams…},即表示此consumer目前所消费的topic + partitions列表.</p>
</li>
<li><p>Consumer offset Tracking: 用来跟踪每个consumer目前所消费的partition中最大的offset.<br> 格式:/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]–&gt;offset_value<br> 此znode为持久节点,可以看出offset跟group_id有关,以表明当group中一个消费者失效,其他consumer可以继续消费.</p>
</li>
<li><p>Partition Owner registry: 用来标记partition被哪个consumer消费.临时znode<br> 格式:/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]–&gt;consumer_node_id当consumer启动时,所触发的操作:</p>
<p>  A) 首先进行”Consumer id Registry”;<br>  B) 然后在”Consumer id Registry”节点下注册一个watch用来监听当前group中其他consumer的”leave”和”join”;只要此znode path下节点列表变更,都会触发此group下consumer的负载均衡.(比如一个consumer失效,那么其他consumer接管partitions).<br>  C) 在”Broker id registry”节点下,注册一个watch用来监听broker的存活情况;如果broker列表变更,将会触发所有的groups下的consumer重新balance.</p>
</li>
</ol>
<p><img src="/images/100013.png" alt="avatar"></p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1) Producer端使用zookeeper用来&quot;发现&quot;broker列表,以及和Topic下每个partition leader建立socket连接并发送消息.</span><br><span class="line">2) Broker端使用zookeeper用来注册broker信息,已经监测partitionleader存活性.</span><br><span class="line">3) Consumer端使用zookeeper用来注册consumer信息,其中包括consumer消费的partition列表等,同时也用来发现broker列表,并和partition leader建立socket连接,并获取消息.</span><br></pre></td></tr></table></figure>
<h4 id="四、主要配置"><a href="#四、主要配置" class="headerlink" title="四、主要配置"></a>四、主要配置</h4><p>1、Broker配置<br><img src="/images/100014.png" alt="avatar"></p>
<p>2.Consumer主要配置<br><img src="/images/100015.png" alt="avatar"></p>
<p>3.Producer主要配置<br><img src="/images/100016.png" alt="avatar"></p>
<p>以上是关于kafka一些基础说明，在其中我们知道如果要kafka正常运行，必须配置zookeeper，否则无论是kafka集群还是客户端的生存者和消费者都无法正常的工作的，以下是对zookeeper进行一些简单的介绍：</p>
<h4 id="五、zookeeper集群"><a href="#五、zookeeper集群" class="headerlink" title="五、zookeeper集群"></a>五、zookeeper集群</h4><p>zookeeper是一个为分布式应用提供一致性服务的软件，它是开源的Hadoop项目的一个子项目，并根据google发表的一篇论文来实现的。zookeeper为分布式系统提供了高笑且易于使用的协同服务，它可以为分布式应用提供相当多的服务，诸如统一命名服务，配置管理，状态同步和组服务等。zookeeper接口简单，我们不必过多地纠结在分布式系统编程难于处理的同步和一致性问题上，你可以使用zookeeper提供的现成(off-the-shelf)服务来实现来实现分布式系统额配置管理，组管理，Leader选举等功能。</p>
<p>zookeeper集群的安装,准备三台服务器server1:192.168.0.1,server2:192.168.0.2,server3:192.168.0.3.</p>
<p>1)下载zookeeper<br>到<a href="http://zookeeper.apache.org/releases.html去下载最新版本Zookeeper-3.4.5的安装包zookeeper-3.4.5.tar.gz.将文件保存server1的~目录下" target="_blank" rel="noopener">http://zookeeper.apache.org/releases.html去下载最新版本Zookeeper-3.4.5的安装包zookeeper-3.4.5.tar.gz.将文件保存server1的~目录下</a></p>
<p>2)安装zookeeper<br>先在服务器server分别执行a-c步骤<br>a)解压<br>tar -zxvf zookeeper-3.4.5.tar.gz<br>解压完成后在目录~下会发现多出一个目录zookeeper-3.4.5,重新命令为zookeeper<br>b）配置<br>将conf/zoo_sample.cfg拷贝一份命名为zoo.cfg，也放在conf目录下。然后按照如下值修改其中的配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000</span><br><span class="line"># The number of ticks that the initial</span><br><span class="line"># synchronization phase can take</span><br><span class="line">initLimit=10</span><br><span class="line"># The number of ticks that can pass between</span><br><span class="line"># sending a request and getting an acknowledgement</span><br><span class="line">syncLimit=5</span><br><span class="line"># the directory where the snapshot is stored.</span><br><span class="line"># do not use /tmp for storage, /tmp here is just</span><br><span class="line"># example sakes.</span><br><span class="line">dataDir=/home/wwb/zookeeper /data</span><br><span class="line">dataLogDir=/home/wwb/zookeeper/logs</span><br><span class="line"># the port at which the clients will connect</span><br><span class="line">clientPort=2181</span><br><span class="line">#</span><br><span class="line"># Be sure to read the maintenance section of the</span><br><span class="line"># administrator guide before turning on autopurge.</span><br><span class="line">#http://zookeeper.apache.org/doc/ ... html#sc_maintenance</span><br><span class="line">#</span><br><span class="line"># The number of snapshots to retain in dataDir</span><br><span class="line">#autopurge.snapRetainCount=3</span><br><span class="line"># Purge task interval in hours</span><br><span class="line"># Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">#autopurge.purgeInterval=1</span><br><span class="line">server.1=192.168.0.1:3888:4888</span><br><span class="line">server.2=192.168.0.2:3888:4888</span><br><span class="line">server.3=192.168.0.3:3888:4888</span><br></pre></td></tr></table></figure>

<p>tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。</p>
<p>dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。</p>
<p>clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。</p>
<p>initLimit：这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10 秒</p>
<p>syncLimit：这个配置项标识 Leader 与Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是2*2000=4 秒</p>
<p>server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号</p>
<p>注意:dataDir,dataLogDir中的wwb是当前登录用户名，data，logs目录开始是不存在，需要使用mkdir命令创建相应的目录。并且在该目录下创建文件myid,serve1,server2,server3该文件内容分别为1,2,3。</p>
<p>针对服务器server2,server3可以将server1复制到相应的目录，不过需要注意dataDir,dataLogDir目录,并且文件myid内容分别为2,3</p>
<p>3)依次启动server1，server2,server3的zookeeper.<br>/home/wwb/zookeeper/bin/zkServer.sh start,出现类似以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JMX enabled by default</span><br><span class="line">Using config: /home/wwb/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure>

<p>4) 测试zookeeper是否正常工作，在server1上执行以下命令<br>/home/wwb/zookeeper/bin/zkCli.sh -server192.168.0.2:2181,出现类似以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JLine support is enabled</span><br><span class="line">2013-11-27 19:59:40,560 - INFO      [main-SendThread(localhost.localdomain:2181):ClientCnxn$SendThread@736]- Session   establishmentcomplete on server localhost.localdomain/127.0.0.1:2181, sessionid =    0x1429cdb49220000, negotiatedtimeout = 30000</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:None path:null</span><br><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 0] [root@localhostzookeeper2]#</span><br></pre></td></tr></table></figure>
<p>即代表集群构建成功了,如果出现错误那应该是第三部时没有启动好集群，<br>运行，先利用<br>ps aux | grep zookeeper查看是否有相应的进程的，没有话，说明集群启动出现问题，可以在每个服务器上使用<br>./home/wwb/zookeeper/bin/zkServer.sh stop。再依次使用./home/wwb/zookeeper/binzkServer.sh start，这时在执行4一般是没有问题，如果还是有问题，那么先stop再到bin的上级目录执行./bin/zkServer.shstart试试。</p>
<p>注意：zookeeper集群时，zookeeper要求半数以上的机器可用，zookeeper才能提供服务。</p>
<h4 id="六、kafka集群"><a href="#六、kafka集群" class="headerlink" title="六、kafka集群"></a>六、kafka集群</h4><p>(利用上面server1,server2,server3,下面以server1为实例)</p>
<p>1)下载kafka0.8(<a href="http://kafka.apache.org/downloads.html),保存到服务器/home/wwb目录下kafka-0.8.0-beta1-src.tgz(kafka_2.8.0-0.8.0-beta1.tgz)" target="_blank" rel="noopener">http://kafka.apache.org/downloads.html),保存到服务器/home/wwb目录下kafka-0.8.0-beta1-src.tgz(kafka_2.8.0-0.8.0-beta1.tgz)</a></p>
<p>2)解压 tar -zxvf kafka-0.8.0-beta1-src.tgz,产生文件夹kafka-0.8.0-beta1-src更改为kafka01</p>
<p>3)配置<br>修改kafka01/config/server.properties,其中broker.id,log.dirs,zookeeper.connect必须根据实际情况进行修改，其他项根据需要自行斟酌。大致如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">broker.id=1</span><br><span class="line">port=9091</span><br><span class="line">num.network.threads=2</span><br><span class="line">num.io.threads=2</span><br><span class="line">socket.send.buffer.bytes=1048576</span><br><span class="line">socket.receive.buffer.bytes=1048576</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line">log.dir=./logs</span><br><span class="line">num.partitions=2</span><br><span class="line">log.flush.interval.messages=10000</span><br><span class="line">log.flush.interval.ms=1000</span><br><span class="line">log.retention.hours=168</span><br><span class="line">#log.retention.bytes=1073741824</span><br><span class="line">log.segment.bytes=536870912</span><br><span class="line">num.replica.fetchers=2</span><br><span class="line">log.cleanup.interval.mins=10</span><br><span class="line">zookeeper.connect=192.168.0.1:2181,192.168.0.2:2182,192.168.0.3:2183</span><br><span class="line">zookeeper.connection.timeout.ms=1000000</span><br><span class="line">kafka.metrics.polling.interval.secs=5</span><br><span class="line">kafka.metrics.reporters=kafka.metrics.KafkaCSVMetricsReporter</span><br><span class="line">kafka.csv.metrics.dir=/tmp/kafka_metrics</span><br><span class="line">kafka.csv.metrics.reporter.enabled=false</span><br></pre></td></tr></table></figure>
<p>4）初始化因为kafka用scala语言编写，因此运行kafka需要首先准备scala相关环境。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; cd kafka01</span><br><span class="line">&gt; ./sbt update</span><br><span class="line">&gt; ./sbt package</span><br><span class="line">&gt; ./sbt assembly-package-dependency</span><br></pre></td></tr></table></figure>
<p>在第二个命令时可能需要一定时间，由于要下载更新一些依赖包。所以请大家 耐心点。</p>
<p>5) 启动kafka01<br> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;JMX_PORT=9997 bin/kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure><br>a)kafka02操作步骤与kafka01雷同，不同的地方如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">修改kafka02/config/server.properties</span><br><span class="line">broker.id=2</span><br><span class="line">port=9092</span><br><span class="line">##其他配置和kafka-0保持一致</span><br><span class="line">启动kafka02</span><br><span class="line">JMX_PORT=9998 bin/kafka-server-start.shconfig/server.properties &amp;</span><br></pre></td></tr></table></figure>
<p>b)kafka03操作步骤与kafka01雷同，不同的地方如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">修改kafka03/config/server.properties</span><br><span class="line">broker.id=3</span><br><span class="line">port=9093</span><br><span class="line">##其他配置和kafka-0保持一致</span><br><span class="line">启动kafka02</span><br><span class="line">JMX_PORT=9999 bin/kafka-server-start.shconfig/server.properties &amp;</span><br></pre></td></tr></table></figure>

<p>6)创建Topic(包含一个分区，三个副本)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;bin/kafka-create-topic.sh--zookeeper 192.168.0.1:2181 --replica 3 --partition 1 --topicmy-replicated-topic</span><br></pre></td></tr></table></figure>
<p>7)查看topic情况</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;bin/kafka-list-top.sh --zookeeper 192.168.0.1:2181</span><br><span class="line">topic: my-replicated-topic  partition: 0 leader: 1  replicas: 1,2,0  isr: 1,2,0</span><br></pre></td></tr></table></figure>
<p>8)创建发送者</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;bin/kafka-console-producer.sh--broker-list 192.168.0.1:9091 --topic my-replicated-topic</span><br><span class="line">my test message1</span><br><span class="line">my test message2</span><br><span class="line">^C</span><br></pre></td></tr></table></figure>
<p>9)创建消费者</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;bin/kafka-console-consumer.sh --zookeeper127.0.0.1:2181 --from-beginning --topic my-replicated-topic</span><br><span class="line">...</span><br><span class="line">my test message1</span><br><span class="line">my test message2</span><br><span class="line">^C</span><br></pre></td></tr></table></figure>
<p>10)杀掉server1上的broker</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;pkill -9 -f config/server.properties</span><br><span class="line">11)查看topic</span><br><span class="line">&gt;bin/kafka-list-top.sh --zookeeper192.168.0.1:2181</span><br><span class="line">topic: my-replicated-topic  partition: 0 leader: 1  replicas: 1,2,0  isr: 1,2,0</span><br><span class="line">发现topic还正常的存在</span><br></pre></td></tr></table></figure>
<p>11）创建消费者，看是否能查询到消息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;bin/kafka-console-consumer.sh --zookeeper192.168.0.1:2181 --from-beginning --topic my-replicated-topic</span><br><span class="line">...</span><br><span class="line">my test message 1</span><br><span class="line">my test message 2</span><br><span class="line">^C</span><br><span class="line">说明一切都是正常的。</span><br></pre></td></tr></table></figure>
<p>OK,以上就是对Kafka个人的理解，不对之处请大家及时指出。</p>
<h4 id="补充说明："><a href="#补充说明：" class="headerlink" title="补充说明："></a>补充说明：</h4><p>1、public Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; createMessageStreams(Map&lt;String, Integer&gt; topicCountMap)，其中该方法的参数Map的key为topic名称，value为topic对应的分区数，譬如说如果在kafka中不存在相应的topic时，则会创建一个topic，分区数为value，如果存在的话，该处的value则不起什么作用</p>
<p>2、关于生产者向指定的分区发送数据，通过设置partitioner.class的属性来指定向那个分区发送数据，如果自己指定必须编写相应的程序，默认是kafka.producer.DefaultPartitioner,分区程序是基于散列的键。</p>
<p>3、在多个消费者读取同一个topic的数据，为了保证每个消费者读取数据的唯一性，必须将这些消费者group_id定义为同一个值，这样就构建了一个类似队列的数据结构，如果定义不同，则类似一种广播结构的。</p>
<p>4、在consumerapi中，参数设计到数字部分，类似Map&lt;String,Integer&gt;,<br>numStream,指的都是在topic不存在的时，会创建一个topic，并且分区个数为Integer,numStream,注意如果数字大于broker的配置中num.partitions属性，会以num.partitions为依据创建分区个数的。</p>
<p>5、producerapi，调用send时，如果不存在topic，也会创建topic，在该方法中没有提供分区个数的参数，在这里分区个数是由服务端broker的配置中num.partitions属性决定的</p>
]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
  </entry>
  <entry>
    <title>Mysql中in和exist的区别</title>
    <url>/2025562487.html</url>
    <content><![CDATA[<h3 id="in和exists的区别"><a href="#in和exists的区别" class="headerlink" title="in和exists的区别"></a>in和exists的区别</h3><p><em>转自：<a href="https://www.cnblogs.com/zhuyeshen/p/10955417.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhuyeshen/p/10955417.html</a><br>参考：<a href="http://www.pianshen.com/article/534497498/" target="_blank" rel="noopener">http://www.pianshen.com/article/534497498/</a><br>&#8195;&#8195;<a href="https://www.cnblogs.com/xiaoxiong-kankan/p/7928153.html" target="_blank" rel="noopener">https://www.cnblogs.com/xiaoxiong-kankan/p/7928153.html</a></em></p>
<h4 id="表结构"><a href="#表结构" class="headerlink" title="表结构"></a>表结构</h4><p>首先，查询中涉及到的两个表，一个user和一个order表，具体表的内容如下：</p>
<p>user表：<br><img src="/images/100001.png" alt="avatar"></p>
<p>order表：<br><img src="/images/100002.png" alt="avatar"></p>
<a id="more"></a>
<h4 id="in查询"><a href="#in查询" class="headerlink" title="in查询"></a>in查询</h4><p>确定给定的值是否与子查询或列表中的值相匹配。in在查询的时候，首先查询子查询的表，然后将内表和外表做一个笛卡尔积，然后按照条件进行筛选。所以相对内表比较小的时候，in的速度较快。</p>
<p>具体sql语句如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 1 SELECT</span><br><span class="line"> 2     *</span><br><span class="line"> 3 FROM</span><br><span class="line"> 4     `user`</span><br><span class="line"> 5 WHERE</span><br><span class="line"> 6     `user`.id IN (</span><br><span class="line"> 7         SELECT</span><br><span class="line"> 8             `order`.user_id</span><br><span class="line"> 9         FROM</span><br><span class="line">10             `order`</span><br><span class="line">11     )</span><br></pre></td></tr></table></figure>
<p>这条语句很简单，通过子查询查到的user_id 的数据，去匹配user表中的id然后得到结果。该语句执行结果如下：<br><img src="/images/100003.png" alt="avatar"></p>
<p>它的执行流程是什么样子的呢？让我们一起来看一下。</p>
<p>首先，在数据库内部，查询子查询，执行如下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    `order`.user_id</span><br><span class="line">FROM</span><br><span class="line">    `order`</span><br></pre></td></tr></table></figure>
<p>执行完毕后，得到结果如下：<br><img src="/images/100004.png" alt="avatar"><br>此时，将查询到的结果和原有的user表做一个笛卡尔积，结果如下：<br><img src="/images/100005.png" alt="avatar"><br>此时，再根据我们的user.id IN order.user_id的条件，将结果进行筛选（既比较id列和user_id 列的值是否相等，将不相等的删除）。最后，得到两条符合条件的数据。<br><img src="/images/100006.png" alt="avatar">
　　　　</p>
<h4 id="exists"><a href="#exists" class="headerlink" title="exists"></a>exists</h4><p>指定一个子查询，检测行的存在。遍历循环外表，然后看外表中的记录有没有和内表的数据一样的。匹配上就将结果放入结果集中。</p>
<p>具体sql语句如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> 1 SELECT</span><br><span class="line"> 2     `user`.*</span><br><span class="line"> 3 FROM</span><br><span class="line"> 4     `user`</span><br><span class="line"> 5 WHERE</span><br><span class="line"> 6     EXISTS (</span><br><span class="line"> 7         SELECT</span><br><span class="line"> 8             `order`.user_id</span><br><span class="line"> 9         FROM</span><br><span class="line">10             `order`</span><br><span class="line">11         WHERE</span><br><span class="line">12             `user`.id = `order`.user_id</span><br><span class="line">13     )</span><br></pre></td></tr></table></figure>
<p>这条sql语句的执行结果和上面的in的执行结果是一样的:<br><img src="/images/100007.png" alt="avatar"></p>
<p>但是，不一样的是它们的执行流程完全不一样：</p>
<p>使用exists关键字进行查询的时候，首先，我们先查询的不是子查询的内容，而是查我们的主查询的表，也就是说，我们先执行的sql语句是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT `user`.* FROM `user`</span><br></pre></td></tr></table></figure>
<p>得到的结果如下：<br><img src="/images/100008.png" alt="avatar"><br>然后，根据表的每一条记录，执行以下语句，依次去判断where后面的条件是否成立：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">EXISTS (</span><br><span class="line">        SELECT</span><br><span class="line">            `order`.user_id</span><br><span class="line">        FROM</span><br><span class="line">            `order`</span><br><span class="line">        WHERE</span><br><span class="line">            `user`.id = `order`.user_id</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>如果成立则返回true不成立则返回false。如果返回的是true的话，则该行结果保留，如果返回的是false的话，则删除该行，最后将得到的结果返回。</p>
<h4 id="区别及应用场景"><a href="#区别及应用场景" class="headerlink" title="区别及应用场景"></a>区别及应用场景</h4><p>in 和 exists的区别: 如果子查询得出的结果集记录较少，主查询中的表较大且又有索引时应该用in, 反之如果外层的主查询记录较少，子查询中的表大，又有索引时使用exists。其实我们区分in和exists主要是造成了驱动顺序的改变(这是性能变化的关键)，如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询，所以我们会以驱动表的快速返回为目标，那么就会考虑到索引及结果集的关系了 ，另外IN时不对NULL进行处理。</p>
<p>in 是把外表和内表作hash 连接，而exists是对外表作loop循环，每次loop循环再对内表进行查询。一直以来认为exists比in效率高的说法是不准确的。</p>
<h4 id="not-in-和not-exists"><a href="#not-in-和not-exists" class="headerlink" title="not in 和not exists"></a>not in 和not exists</h4><p>如果查询语句使用了not in 那么内外表都进行全表扫描，没有用到索引；而not extsts 的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</p>
]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
  </entry>
  <entry>
    <title>电商系统中关于订单和库存的几个问题</title>
    <url>/3786447307.html</url>
    <content><![CDATA[<p><em>原创整理，转载请注明出处</em></p>
<h3 id="电商系统关于订单和库存的几个问题"><a href="#电商系统关于订单和库存的几个问题" class="headerlink" title="电商系统关于订单和库存的几个问题"></a>电商系统关于订单和库存的几个问题</h3><p>最近参加面试，被问及电商项目中如何处理并发情况下用户下单、减库存、事务一致性等问题。由于之前的项目类似于一个单体项目，对于高并发、高可用的的设计未有考虑，故面试问答很不流畅，有一定的相关概念，却没有一整套解决相关问题的流程。所以决定做个总结，以备后用。<br>总结起来有一下几个问题：</p>
<a id="more"></a>
<ol>
<li>系统是如何保证高并发下用户体验的？</li>
<li>扣减库存是下单扣减还是支付扣减？为什么？</li>
<li>对于库存的扣减，如何保证不超卖？</li>
<li>如何控制恶意库存占用？</li>
</ol>
<h4 id="问题一：系统是如何保证高并发下用户体验的？"><a href="#问题一：系统是如何保证高并发下用户体验的？" class="headerlink" title="问题一：系统是如何保证高并发下用户体验的？"></a>问题一：系统是如何保证高并发下用户体验的？</h4><p>首先我们来明确一个概念：并发。并发是什么？有人说并发就是两个或多个任务一起执行。在单核CPU中，执行任务的线程是交替获取cup时间切片的，由于切换并执行非常快，在外界看来，多个任务是一起执行的。实际上，它们是交替执行的。在虚拟机中，有个专门的内存区域叫程序计数器，它的目的就是记录每个线程执行的字节码的行号指示器，以应对线程切换执行时，切入执行时机的问题。与并发类似的概念是并行，它是真实地同步执行，所以只有在多核CPU中才会有并行地概念。<br>所以，对于高并发用户体验可用性问题，实际上就是系统地性能能达到什么样地程度问题。<br>这当中，数据库的访问性能往往又是系统的性能瓶颈。根据经验数据，用户在访问互联网时，超过90%的操作只是读取数据，提交、修改的数据不到10%。因此可以将内容相对固定、主要供用户浏览的页面生产缓存，而无需访问数据库。<br>对于静态内容（网页、图片、音频文件、脚本文件等）可以选择CDN（Content Delivery Network，内容分发网络）方式发布，从而通过专业内容发布服务提高网站访问速度。频繁修改的数据可以采用缓存的办法处理。</p>
<h4 id="问题二：扣减库存是下单扣减还是支付扣减？为什么？"><a href="#问题二：扣减库存是下单扣减还是支付扣减？为什么？" class="headerlink" title="问题二：扣减库存是下单扣减还是支付扣减？为什么？"></a>问题二：扣减库存是下单扣减还是支付扣减？为什么？</h4><p>核心思路是预锁库存，即下单时扣减，支付设置一个有效期，超过有效期释放库存。对于可能的恶意库存占用，限定用户在某个时间内的购买数量（或者达到一定数量提示其转到大客户购买处，单独处理）（PS：有位面试官牢牢抓住恶意库存占用问题问，最后聊得很尴尬，其实这本质上是产品得取舍问题，哪怕是支付后扣减，也有诸如支付了却提示库存不足得问题，这就要看产品根据实际情况做出权衡，技术上总归有实现思路的）。</p>
<p>摘抄他人总结的12306的实现思路<br>因为买火车票和购物不一样，购物可以付款后出库，但是买票这种，支付前就必须出库，因此，要将出库过程提前， 只有出库成功，才能生成订单，同样要引入redis库存</p>
<ol>
<li><p>先扣缓存中的库存，扣除成功后，然后才可以去扣mysql中的库存</p>
</li>
<li><p>如果扣除缓存中的库存失败，就会挡在外面，返回库存不足，这些请求不会穿刺到mysql中，挡住了大多数的请求压力。</p>
</li>
<li><p>redis库存会和mysql库存不一致，极端情况下是肯定有的，需要进行库存同步</p>
<p>3.1 当缓存库存比数据库库存多，那么就会出现，查询有票，但是就无法下单，下单的时候就说库存不足， 这样也不会超卖，当redis的库存多的那部分扣完了，就可以把请求全部当在外面了。 对于12306，有时候，查询的时候有票，但是下单的时候返回库存不足，然后重新查询发现还是有库存， 这种情况应该就是redis中库存和mysql中库存不一致造成的。</p>
<p>3.2 当缓存库存比数据库缓存少，那么不会出问题，只会出现有票，但是没有出售的情况，等完成库存同步一下， 明天又准确了。</p>
<p>3.3 当然，mysql扣除库存的部分，还需要在前面加入队列缓冲，避免请求过多，让应用程序或数据库崩溃。</p>
</li>
</ol>
<h4 id="问题三：对于库存的扣减，如何保证不超卖？"><a href="#问题三：对于库存的扣减，如何保证不超卖？" class="headerlink" title="问题三：对于库存的扣减，如何保证不超卖？"></a>问题三：对于库存的扣减，如何保证不超卖？</h4><p>方式一<br>可以对读操作加上显式锁（即在select …语句最后加上for update）这样一来用户1在进行读操作时用户2就需要排队等待了<br>但是问题来了，如果该商品很热门并发量很高那么效率就会大大的下降，怎么解决？<br>我们可以有条件有选择的在读操作上加锁，比如可以对库存做一个判断，当库存小于一个量时开始加锁，让购买者排队，这样一来就解决了超卖现象。<br>方式二<br>数据库表增加版本字段如version，每次修改时版本号+1<br>如果更新操作顺序执行，则数据的版本（version）依次递增，不会产生冲突。但是如果发生有不同的业务操作对同一版本的数据进行修改，那么，先提交的操作（图中B）会把数据version更新为2，当A在B之后提交更新时发现数据的version已经被修改了，那么A的更新操作会失败。<br>PDO update更新后，不但要验证返回状态是否为true,并且同时验证影响行数是否大于0<br>方式三 redis的队列来实现<br>将要促销的商品数量以队列的方式存入redis中，每当用户抢到一件促销商品则从队列中删除一个数据，确保商品不会超卖。这个操作起来很方便，而且效率极高，最终我们采取这种方式来实现</p>
<h4 id="问题四-如何控制恶意库存占用？"><a href="#问题四-如何控制恶意库存占用？" class="headerlink" title="问题四:如何控制恶意库存占用？"></a>问题四:如何控制恶意库存占用？</h4><p>首先，这个问题是否真实存在，或者说发生概率有多大？</p>
<p>产品设计有时候是一个博弈的过程，如果一个功能需要付出10的成本，却只覆盖了1的需求，这个功能是否真的需要投入开发？举个栗子，打车平台的车主入驻需要验证车主真实身份，在真实性安全性方面做好保障，某打车平台A在车主入驻的时候需要填写繁复的资料，比如验证身份证，举着身份证拍照等，结果导致只有5%的车主愿意走完整个验证流程，但实际上虚假的车主可能仅占1%，为了这1%的车主放弃了另外94%的服务者，是不是太亏了？</p>
<p>当然不是说问题小，就可以不去解决，但是可以考虑有没有侧面的低成本解决方案。</p>
<p>延续上面的例子，另外一个打车平台B在车主入驻的时候仅需要填写基础资料，那如何验证司机真实性呢？机智的B公司邀请司机绑定银行卡，载客收益到账是司机的最基本需求，而银行卡是与个人身份绑定的，已经经过银行验证过用户真实性的，较低的注册成本使得大部分的司机都愿意走完注册流程，开始使用B产品。</p>
<p>下面正面回答下问题，因为非电商行业，所以仅靠逻辑推理，如有错误，请及时沟通</p>
<p>1、反作弊策略。定义恶意下单的时间频次，IP或者UID信息，当操作行为触发反作弊策略后，可以对该商品的库存锁定机制做调整，对于某些运营活动的爆款需要设立白名单或者调整反作弊策略；</p>
<p>2、允许超卖。库存100件，允许超卖x%；</p>
<p>3、调整库存锁定/解锁策略，比如在下单后5min才触发库存锁定，或者下单后15min未支付则解除库存锁定；</p>
<p>5、当库存小于一定量时，界面设计上则显示库存紧张，以用户支付请求为节点，“先支付先得”。</p>
<p>参考：<br>电商产品如何防止恶意下单导致的库存被占用？<a href="https://www.pmcaff.com/discuss/index/1000000000162678?from=related&amp;pmc_param%5Bentry_id%5D=1000000000163080" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/index/1000000000162678?from=related&amp;pmc_param%5Bentry_id%5D=1000000000163080</a><br>高并发电商平台设计 <a href="http://www.legendshop.cn/new_547.html" target="_blank" rel="noopener">http://www.legendshop.cn/new_547.html</a><br>用Redis轻松实现秒杀系统 <a href="https://blog.csdn.net/lida1234567/article/details/82866617" target="_blank" rel="noopener">https://blog.csdn.net/lida1234567/article/details/82866617</a><br>如何解决电商网站超卖现象 <a href="https://blog.csdn.net/u013521220/article/details/78839307" target="_blank" rel="noopener">https://blog.csdn.net/u013521220/article/details/78839307</a><br>关于电商库存扣除实现思路 <a href="http://www.fecmall.com/topic/648" target="_blank" rel="noopener">http://www.fecmall.com/topic/648</a></p>
]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
  </entry>
  <entry>
    <title>MyBatis面试题：# 和 $ 的区别是什么</title>
    <url>/182044780.html</url>
    <content><![CDATA[<p><em>转载自：Mybatis中文网：<a href="http://www.mybatis.cn/" target="_blank" rel="noopener">http://www.mybatis.cn/</a></em></p>
<p>经常碰到这样的面试题目：#{}和${}的区别是什么？</p>
<p>正确的答案是：<strong>#{}是预编译处理，${}是字符串替换。</strong></p>
<p>备注：${}是插值，插值的新认识见： <a href="http://www.mybatis.cn/archives/653.html" target="_blank" rel="noopener">http://www.mybatis.cn/archives/653.html</a></p>
<a id="more"></a>
<ol>
<li><p>mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值。</p>
</li>
<li><p>mybatis在处理${}时，就是把${}替换成变量的值。</p>
</li>
<li><p>使用#{}可以有效的防止SQL注入，提高系统安全性。原因在于：预编译机制。预编译完成之后，SQL的结构已经固定，即便用户输入非法参数，也不会对SQL的结构产生影响，从而避免了潜在的安全风险。</p>
</li>
<li><p>预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。</p>
</li>
</ol>
<p>补充1:</p>
<p>$符号一般用来当作占位符，常使用Linux脚本的人应该对此有更深的体会吧。例如：$1，$2等等表示输入参数的占位符。知道了这点就能很容易区分$和#，从而不容易记错了。</p>
<p>补充2：</p>
<p>万事洞明皆学问，对于mybatis与sql这两门技术而言，看似简单，但是深挖进去会发现里面的东西还是挺多的。要想成为一名合格的开发人员，需要不断的去学习，更需要不断的去思考。可以参考：<a href="http://www.mybatis.cn/category/mysql-mybatis/" target="_blank" rel="noopener">http://www.mybatis.cn/category/mysql-mybatis/</a> ，系统的学习sql和mybatis的东西，这是本站2019年计划出版的小册子，欢迎试读。</p>
<p>补充3：</p>
<p>有网友提问：既然${}会引起sql注入，为什么有了#{}还需要有${}呢？那其存在的意义是什么？<br>可以这么去理解：#{}主要用于预编译，而预编译的场景其实非常受限，而${}用于替换，很多场景会出现替换，而这种场景可不是预编译，例如：MyBatis XML配置对抗MyBatis注解的一大杀器：SQL片段，抽取可重用的SQL语句。</p>
]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
  </entry>
  <entry>
    <title>Minor GC、Major GC和Full GC之间的区别</title>
    <url>/2196748335.html</url>
    <content><![CDATA[<p><em>原文链接： javacodegeeks 翻译： ImportNew.com - 光光头去打酱油</em></p>
<p><em>译文链接： <a href="http://www.importnew.com/15820.html" target="_blank" rel="noopener">http://www.importnew.com/15820.html</a></em></p>
<p>在 Plumbr 从事 GC 暂停检测相关功能的工作时，我被迫用自己的方式，通过大量文章、书籍和演讲来介绍我所做的工作。在整个过程中，经常对 Minor、Major、和 Full GC 事件的使用感到困惑。这也是我写这篇博客的原因，我希望能清楚地解释这其中的一些疑惑。<br>文章要求读者熟悉 JVM 内置的通用垃圾回收原则。堆内存划分为 Eden、Survivor 和 Tenured/Old 空间，代假设和其他不同的 GC 算法超出了本文讨论的范围。</p>
<a id="more"></a>
<h3 id="Minor-GC"><a href="#Minor-GC" class="headerlink" title="Minor GC"></a>Minor GC</h3><p>从年轻代空间（包括 Eden 和 Survivor 区域）回收内存被称为 Minor GC。这一定义既清晰又易于理解。但是，当发生Minor GC事件的时候，有一些有趣的地方需要注意到：</p>
<p>当 JVM 无法为一个新的对象分配空间时会触发 Minor GC，比如当 Eden 区满了。所以分配率越高，越频繁执行 Minor GC。<br>内存池被填满的时候，其中的内容全部会被复制，指针会从0开始跟踪空闲内存。Eden 和 Survivor 区进行了标记和复制操作，取代了经典的标记、扫描、压缩、清理操作。所以 Eden 和 Survivor 区不存在内存碎片。写指针总是停留在所使用内存池的顶部。<br>执行 Minor GC 操作时，不会影响到永久代。从永久代到年轻代的引用被当成 GC roots，从年轻代到永久代的引用在标记阶段被直接忽略掉。<br>质疑常规的认知，所有的 Minor GC 都会触发“全世界的暂停（stop-the-world）”，停止应用程序的线程。对于大部分应用程序，停顿导致的延迟都是可以忽略不计的。其中的真相就 是，大部分 Eden 区中的对象都能被认为是垃圾，永远也不会被复制到 Survivor 区或者老年代空间。如果正好相反，Eden 区大部分新生对象不符合 GC 条件，Minor GC 执行时暂停的时间将会长很多。<br>所以 Minor GC 的情况就相当清楚了——每次 Minor GC 会清理年轻代的内存。</p>
<h3 id="Major-GC-vs-Full-GC"><a href="#Major-GC-vs-Full-GC" class="headerlink" title="Major GC vs Full GC"></a>Major GC vs Full GC</h3><p>大家应该注意到，目前，这些术语无论是在 JVM 规范还是在垃圾收集研究论文中都没有正式的定义。但是我们一看就知道这些在我们已经知道的基础之上做出的定义是正确的，Minor GC 清理年轻带内存应该被设计得简单：<br><strong>Major GC 是清理永久代。</strong></p>
<p>Full GC 是清理整个堆空间—包括年轻代和永久代。<br>很不幸，实际上它还有点复杂且令人困惑。首先，许多 Major GC 是由 Minor GC 触发的，所以很多情况下将这两种 GC 分离是不太可能的。另一方面，许多现代垃圾收集机制会清理部分永久代空间，所以使用“cleaning”一词只是部分正确。<br>这使得我们不用去关心到底是叫 Major GC 还是 Full GC，大家应该关注当前的 GC 是否停止了所有应用程序的线程，还是能够并发的处理而不用停掉应用程序的线程。<br>这种混乱甚至内置到 JVM 标准工具。</p>
<p>下面一个例子很好的解释了我的意思。让我们比较两个不同的工具 Concurrent Mark 和 Sweep collector (-XX:+UseConcMarkSweepGC)在 JVM 中运行时输出的跟踪记录。<br>第一次尝试通过 jstat 输出：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1 my-precious: me$ jstat -gc -t 4235 1s</span><br><span class="line">12345678910111213 Time S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT    5.7 34048.0 34048.0  0.0   34048.0 272640.0 194699.7 1756416.0   181419.9  18304.0 17865.1 2688.0 2497.6      3    0.275   0      0.000    0.275 6.7 34048.0 34048.0 34048.0  0.0   272640.0 247555.4 1756416.0   263447.9  18816.0 18123.3 2688.0 2523.1      4    0.359   0      0.000    0.359 7.7 34048.0 34048.0  0.0   34048.0 272640.0 257729.3 1756416.0   345109.8  19072.0 18396.6 2688.0 2550.3      5    0.451   0      0.000    0.451 8.7 34048.0 34048.0 34048.0 34048.0 272640.0 272640.0 1756416.0  444982.5  19456.0 18681.3 2816.0 2575.8      7    0.550   0      0.000    0.550 9.7 34048.0 34048.0 34046.7  0.0   272640.0 16777.0  1756416.0   587906.3  20096.0 19235.1 2944.0 2631.8      8    0.720   0      0.000    0.72010.7 34048.0 34048.0  0.0   34046.2 272640.0 80171.6  1756416.0   664913.4  20352.0 19495.9 2944.0 2657.4      9    0.810   0      0.000    0.81011.7 34048.0 34048.0 34048.0  0.0   272640.0 129480.8 1756416.0   745100.2  20608.0 19704.5 2944.0 2678.4     10    0.896   0      0.000    0.89612.7 34048.0 34048.0  0.0   34046.6 272640.0 164070.7 1756416.0   822073.7  20992.0 19937.1 3072.0 2702.8     11    0.978   0      0.000    0.97813.7 34048.0 34048.0 34048.0  0.0   272640.0 211949.9 1756416.0   897364.4  21248.0 20179.6 3072.0 2728.1     12    1.087   1      0.004    1.09114.7 34048.0 34048.0  0.0   34047.1 272640.0 245801.5 1756416.0   597362.6  21504.0 20390.6 3072.0 2750.3     13    1.183   2      0.050    1.23315.7 34048.0 34048.0  0.0   34048.0 272640.0 21474.1  1756416.0   757347.0  22012.0 20792.0 3200.0 2791.0     15    1.336   2      0.050    1.38616.7 34048.0 34048.0 34047.0  0.0   272640.0 48378.0  1756416.0   838594.4  22268.0 21003.5 3200.0 2813.2     16    1.433   2      0.050    1.484</span><br></pre></td></tr></table></figure>
<p>这个片段是 JVM 启动后第17秒提取的。基于该信息，我们可以得出这样的结果，运行了12次 Minor GC、2次 Full GC，时间总跨度为50毫秒。通过 jconsole 或者 jvisualvm 这样的基于GUI的工具你能得到同样的结果。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1 java -XX:+PrintGCDetails -XX:+UseConcMarkSweepGC eu.plumbr.demo.GarbageProducer</span><br><span class="line">12345678910111213141516171819 3.157: [GC (Allocation Failure) 3.157: [ParNew: 272640K-&gt;34048K(306688K), 0.0844702 secs] 272640K-&gt;69574K(2063104K), 0.0845560 secs] [Times: user=0.23 sys=0.03, real=0.09 secs] 4.092: [GC (Allocation Failure) 4.092: [ParNew: 306688K-&gt;34048K(306688K), 0.1013723 secs] 342214K-&gt;136584K(2063104K), 0.1014307 secs] [Times: user=0.25 sys=0.05, real=0.10 secs] ... cut for brevity ...11.292: [GC (Allocation Failure) 11.292: [ParNew: 306686K-&gt;34048K(306688K), 0.0857219 secs] 971599K-&gt;779148K(2063104K), 0.0857875 secs] [Times: user=0.26 sys=0.04, real=0.09 secs] 12.140: [GC (Allocation Failure) 12.140: [ParNew: 306688K-&gt;34046K(306688K), 0.0821774 secs] 1051788K-&gt;856120K(2063104K), 0.0822400 secs] [Times: user=0.25 sys=0.03, real=0.08 secs] 12.989: [GC (Allocation Failure) 12.989: [ParNew: 306686K-&gt;34048K(306688K), 0.1086667 secs] 1128760K-&gt;931412K(2063104K), 0.1087416 secs] [Times: user=0.24 sys=0.04, real=0.11 secs] 13.098: [GC (CMS Initial Mark) [1 CMS-initial-mark: 897364K(1756416K)] 936667K(2063104K), 0.0041705 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 13.102: [CMS-concurrent-mark-start]13.341: [CMS-concurrent-mark: 0.238/0.238 secs] [Times: user=0.36 sys=0.01, real=0.24 secs] 13.341: [CMS-concurrent-preclean-start]13.350: [CMS-concurrent-preclean: 0.009/0.009 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 13.350: [CMS-concurrent-abortable-preclean-start]13.878: [GC (Allocation Failure) 13.878: [ParNew: 306688K-&gt;34047K(306688K), 0.0960456 secs] 1204052K-&gt;1010638K(2063104K), 0.0961542 secs] [Times: user=0.29 sys=0.04, real=0.09 secs] 14.366: [CMS-concurrent-abortable-preclean: 0.917/1.016 secs] [Times: user=2.22 sys=0.07, real=1.01 secs] 14.366: [GC (CMS Final Remark) [YG occupancy: 182593 K (306688 K)]14.366: [Rescan (parallel) , 0.0291598 secs]14.395: [weak refs processing, 0.0000232 secs]14.395: [class unloading, 0.0117661 secs]14.407: [scrub symbol table, 0.0015323 secs]14.409: [scrub string table, 0.0003221 secs][1 CMS-remark: 976591K(1756416K)] 1159184K(2063104K), 0.0462010 secs] [Times: user=0.14 sys=0.00, real=0.05 secs] 14.412: [CMS-concurrent-sweep-start]14.633: [CMS-concurrent-sweep: 0.221/0.221 secs] [Times: user=0.37 sys=0.00, real=0.22 secs] 14.633: [CMS-concurrent-reset-start]14.636: [CMS-concurrent-reset: 0.002/0.002 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]</span><br></pre></td></tr></table></figure>
<p>在点头同意这个结论之前，让我们看看来自同一个 JVM 启动收集的垃圾收集日志的输出。显然- XX ： + PrintGCDetails 告诉我们一个不同且更详细的故事：</p>
<p>基于这些信息，我们可以看到12次 Minor GC 后开始有些和上面不一样了。没有运行两次 Full GC，这不同的地方在于单个 GC 在永久代中不同阶段运行了两次：</p>
<p>最初的标记阶段，用了0.0041705秒也就是4ms左右。这个阶段会暂停“全世界（ stop-the-world）”的事件，停止所有应用程序的线程，然后开始标记。<br>并行执行标记和清洗阶段。这些都是和应用程序线程并行的。<br>最后 Remark 阶段，花费了0.0462010秒约46ms。这个阶段会再次暂停所有的事件。<br>并行执行清理操作。</p>
<p>正如其名，此阶段也是并行的，不会停止其他线程。<br>所以，正如我们从垃圾回收日志中所看到的那样，实际上只是执行了 Major GC 去清理老年代空间而已，而不是执行了两次 Full GC。<br>如果你是后期做决 定的话，那么由 jstat 提供的数据会引导你做出正确的决策。它正确列出的两个暂停所有事件的情况，导致所有线程停止了共计50ms。但是如果你试图优化吞吐量，你会被误导的。清 单只列出了回收初始标记和最终 Remark 阶段，jstat的输出看不到那些并发完成的工作。</p>
<p>结论<br>考虑到这种情况，最好避免以 Minor、Major、Full GC 这种方式来思考问题。而应该监控应用延迟或者吞吐量，然后将 GC 事件和结果联系起来。<br>随着这些 GC 事件的发生，你需要额外的关注某些信息，GC 事件是强制所有应用程序线程停止了还是并行的处理了部分事件。</p>
]]></content>
      <categories>
        <category>Jvm虚拟机</category>
      </categories>
  </entry>
</search>
